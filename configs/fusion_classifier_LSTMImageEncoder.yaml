# Model parameters
model:
  architecture: 'fusion_classifier' # Model architecture: alexnet, resnet18, resnet34, etc.
  img_encoder: 'ImageEncoder'
  pretrained: true        
  weights_path: '/dataset/pretrained_weights/alexnet_weights.pth'   
  input_channels: 3       # Number of input channels (e.g., 3 for RGB, 6 for stereo)
  num_classes_rot: 5
  num_classes_trans: 5
  output_dir: '/tmp_log/'          

# Dataset parameters
dataset:
  root_dir: '/dataset/'
  context_len: 5
  horizon: 3           
  batch_size: 32                                                                       
  num_workers: 4                        
  feature_dim: 3                     

  dataset_dict:
    train:
      {
        euroc: [
          "MH_01_easy", 
          "MH_03_medium",
          "MH_04_difficult",
          "MH_05_difficult",
          "V1_01_easy",
          "V1_03_difficult",
          "V2_01_easy",
          "V2_02_medium",
          "V2_03_difficult"
        ]
      }

    val:
      {
        euroc: [
          "MH_02_easy",
          "V1_02_medium",
        ]
      }
                                                                                         

# Data augmentation and transformation parameters
data_transforms:
  resize: [224, 224]                   
  mean: [0.485, 0.456, 0.406]          
  std: [0.229, 0.224, 0.225]            

optimization:
  optimizer: 'adamw'
  lr: 0.001
  weight_decay: 0.01
  momentum: 0.9

# Training Parameters
training:
  task: 'classification'                
  loss_function: 'CrossEntropyLoss'              
  num_epochs: 25              
  eval_period: 1
  print_period: 10
  save_model_period: 5
  save_statistics_period: 5         

misc:
  seed: 42
  use_wandb: true
  wandb_project: 'ood-slam'
  wandb_entity: 'udem-mila'
  log_dir: '/tmp_log/'
  exp_id: 0
  exp_name: 'fusion_classifier_LSTMImageEncoder_experiment'
  verbose: true
